import pickle, gzip, glob, sys, keras, os
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'  # gets rid of AVX message
import random as rn
import numpy as np
import tensorflow as tf
os.environ['PYTHONHASHSEED'] = '0'
np.random.seed(37)
rn.seed(1254)
tf.set_random_seed(89)
from keras import optimizers
from keras import backend as K
from keras.models import load_model
from keras.layers import *
from keras.models import Sequential
from keras.losses import weighted_categorical_crossentropy
from keras.callbacks import CSVLogger, ModelCheckpoint
from keras.regularizers import *
from keras.utils.generic_utils import get_custom_objects
from keras.layers.advanced_activations import LeakyReLU, ELU
sys.path.insert(0, r'.\libraries')
from kerasLayers import *
from kerasExtras import *
elu = ELU(1)
elu.__name__ = "ELU"



# input_length = None
# line_length = 18
# num_samples = 5000
# num_samples_valid = 2500

#nopad kaggle
input_length = None
line_length = 25
num_samples = 8000
num_samples_valid = 2375

# standard input
train_gen = loadDataGenerator(r".\libraries\datasets\kaggle\trainASM_all_nopad_pooled.pklz", num_samples)
valid_gen = loadDataGenerator(r".\libraries\datasets\kaggle\validASM_all_nopad_pooled.pklz", num_samples_valid)


# pad binary
# line_length = 18
# num_samples = 4000
# num_samples_valid = 1000

# no line pad
# train_gen = loadDataGenerator(r".\kaggle_dataset\vectorized\trainASM_all_pooled.pklz", num_samples)
# valid_gen = loadDataGenerator(r".\kaggle_dataset\vectorized\validASM_all_pooled.pklz", num_samples_valid)

# no pool
# train_gen = loadDataGenerator(r".\libraries\datasets\kaggle\trainASM_all_nopad.pklz", num_samples)
# valid_gen = loadDataGenerator(r".\libraries\datasets\kaggle\validASM_all_nopad.pklz", num_samples_valid)

# window overlap
# train_gen = loadDataGenerator(r".\kaggle_dataset\vectorized\trainASM_all_nopad_pooled_window15.pklz", num_samples)
# valid_gen = loadDataGenerator(r".\kaggle_dataset\vectorized\validASM_all_nopad_pooled_window15.pklz", num_samples_valid)

# train_gen = loadDataGeneratorBinary(r".\libraries\datasets\kagglewindows\windows_exe_dll_kaggle_no50k_pooled.pklz", num_samples)
# valid_gen = loadDataGeneratorBinary(r".\libraries\datasets\kagglewindows\windows_exe_dll_kaggle_validation_no50k_pooled.pklz", num_samples_valid)


# binary nopad 0 day and otherwise (?)
# line_length = 25
# num_samples = 7500
# num_samples_valid = 9100 - 7500
# num_samples_0day = 522   # experimentally

# train_gen = loadDataGeneratorBinary(r".\libraries\datasets\kagglewindows0day\winkaggle_noclass8_nopad_pooled.pklz", num_samples)
# valid_gen = loadDataGeneratorBinary(r".\libraries\datasets\kagglewindows0day\winkaggle_noclass8_validation_nopad_pooled.pklz", num_samples_valid)



# opcodes only 
# line_length = 25
# num_samples = 7500
# num_samples_valid = 9100 - 7500

# train_gen = loadDataGeneratorBinary(r"D:\Research\1_Libraries\datasets\opcodes_windows_exe_dll_kaggle_nopad_pooled.pklz", num_samples)
# valid_gen = loadDataGeneratorBinary(r"D:\Research\1_Libraries\datasets\opcodes_windows_exe_dll_kaggle_validation_nopad_pooled.pklz", num_samples_valid)





# vocab_size = 255
# line_length = 25
# num_samples = 7500
# num_samples_valid = 1600

# binary standard
# train_gen = loadDataGeneratorBinary(r".\libraries\datasets\kagglewindows\windows_exe_dll_kaggle_nopad_pooled.pklz", num_samples)
# valid_gen = loadDataGeneratorBinary(r".\libraries\datasets\kagglewindows\windows_exe_dll_kaggle_validation_nopad_pooled.pklz", num_samples_valid)





# define variables
# batch_size = 1
steps_per_epoch = num_samples/batch_size
valid_steps = num_samples_valid/batch_size  # should be this
epochs = 100




from model_builder import build_model
# model = build_model(input_length, line_length, "cnn", "malware_only")
# model = build_model(input_length, line_length, "convlstm", "malware_only")
# model = build_model(input_length, line_length, "minconvrnn", "malware_only")
# model = build_model(input_length, line_length, "distcnn", "malware_only")


model = build_model(input_length, line_length, "distcnn", "binary")
# model = build_model(input_length, line_length, "distcnn", "binary", extras=["noembed"])




# model = load_model(r"D:\Research\3_Kaggle\kaggle_networks\93. NOPOOL net based on 79\KaggleConv-15.hdf5",
# model = load_model(r".\networks\rnn binary final nets\addconv\KaggleConv-09.hdf5",
                   # custom_objects={'DecayingConvLSTM2D':MinConvRNN,
                                   # 'window_size': window_size ,
                                   # 'ELU': elu,
                                   # }
                   # )

print("Compiling Model and Training")
print()







model.compile(optimizer='rmsprop',
              # loss='categorical_crossentropy',
              loss='binary_crossentropy',
              metrics=['accuracy'])

print(model.summary())




csv_logger = CSVLogger(r'.\networks\KaggleTrainingSeqConv.log')
filepath = r".\networks\KaggleConv-{epoch:02d}.hdf5"
checkpoint = ModelCheckpoint(filepath)

model.fit_generator(train_gen,
                    epochs=epochs,
                    callbacks=[csv_logger, checkpoint],
                    steps_per_epoch=steps_per_epoch, 
                    validation_data=valid_gen,
                    validation_steps = valid_steps,
)
          
          





# C:\altera\13.0\quartus\drivers











