import tensorflow as tf

import numpy as np
import sys

from keras.utils import conv_utils
from tensorflow.python.ops import tensor_array_ops
from tensorflow.python.ops import control_flow_ops
from tensorflow.python.ops import functional_ops
from tensorflow.python.ops import ctc_ops as ctc
import os

sys.path.append('../LeFlow/src')
import processMif as mif



tf.logging.set_verbosity(tf.logging.ERROR)
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'  # gets rid of AVX message


# this is shape (1, 250, 25) which is 1 batch of 250 lines!!!!
# from kerasExtrasLeFlow import *
# train_gen = loadDataGeneratorBinary(r"D:\Research\windows_exe_dll_kaggle_validation_nopad_pooled.pklz", 1)
# mal_in, mal_ans = next(train_gen)
# np.save('binary_mal_in.npy', mal_in)

max_in = np.zeros((1, 6, 6, 25))
mal_in = np.load('binary_mal_in.npy')[:,:25,:]
mal_shape = mal_in.shape
previous_max_shape = max_in.shape
window_size = 25


'''
from keras.models import load_model
# model = load_model(r"model_256embed_globalmax.hdf5",
model = load_model(r"binary_noembed_nopad_pooled.hdf5",
                   custom_objects={'window_size': window_size }
                   )
print(model.summary())
print(model.predict(mal_in))
# '''


'''
# this block saves all weights
# the VM can't load the python3 model because it has python2
# so save all weights with np

# embed version
# raw_embed_weights = model.layers[0].layer.get_weights()
# raw_conv_1_weights = model.layers[2].layer.get_weights()
# raw_conv_2_weights = model.layers[4].layer.get_weights()
# raw_dense_1_weights = model.layers[8].get_weights()
# raw_dense_2_weights = model.layers[9].get_weights()
# embed_weights = tf.Variable(raw_embed_weights[0])

raw_conv_1_weights = model.layers[1].layer.get_weights()
raw_conv_2_weights = model.layers[3].layer.get_weights()
raw_dense_1_weights = model.layers[7].get_weights()
raw_dense_2_weights = model.layers[8].get_weights()

conv_1_kernel = tf.Variable(raw_conv_1_weights[0])
conv_1_bias   = tf.Variable(raw_conv_1_weights[1])
conv_2_kernel = tf.Variable(raw_conv_2_weights[0])
conv_2_bias   = tf.Variable(raw_conv_2_weights[1])
dense_1_w     = tf.Variable(raw_dense_1_weights[0])
dense_1_b     = tf.Variable(raw_dense_1_weights[1])
dense_2_w     = tf.Variable(raw_dense_2_weights[0])
dense_2_b     = tf.Variable(raw_dense_2_weights[1])

all_weights = [
        raw_conv_1_weights[0], 
        raw_conv_1_weights[1], 
        raw_conv_2_weights[0], 
        raw_conv_2_weights[1],
        raw_dense_1_weights[0], 
        raw_dense_1_weights[1], 
        raw_dense_2_weights[0], 
        raw_dense_2_weights[1], 
        # raw_embed_weights[0],
]
np.save("binary_all_weights.npy", all_weights)
0/0
# '''

    
    


all_weights = np.load("binary_all_weights.npy")

shape = list(mal_shape)

in_tensor = tf.placeholder(tf.float32, shape=shape)
#previous_max_tensor = tf.placeholder(tf.float32, shape=previous_max_shape)

conv_1_kernel = tf.Variable(all_weights[0])
conv_1_bias   = tf.Variable(all_weights[1])
conv_2_kernel = tf.Variable(all_weights[2])
conv_2_bias   = tf.Variable(all_weights[3])
dense_1_w     = tf.Variable(all_weights[4])
dense_1_b     = tf.Variable(all_weights[5])
dense_2_w     = tf.Variable(all_weights[6])
dense_2_b     = tf.Variable(all_weights[7])
# embed_weights = tf.Variable(all_weights[8])

add_val       = .5
add_val_tensor= tf.Variable(add_val)
    
init = tf.global_variables_initializer()
# Starting Tensorflow XLA session
with tf.Session() as session:
    session.run(init)
    
    # Generating hardware  
    with tf.device("device:XLA_CPU:0"):
    # if True:
        
        # try to emulate nn exactly
        # embed causes dead nodes due to tf.where 
        # embed = timedist_RESHAPE(in_tensor, 
                         # lambda x: tf.nn.embedding_lookup(embed_weights, tf.cast(x, tf.int32)),
                         # "embed")
                         # )
        
        
        
        
        shape = tf.shape( in_tensor )
        reshaped = tf.reshape( in_tensor, [shape[0] , window_size, window_size, 1] )
        # reshaped = tf.reshape( in_tensor, [shape[0] , window_size, window_size] )
        
        # embed = tf.gather(embed_weights, tf.cast(reshaped, tf.int32)) 
        
        #embed = reshaped
        
        # one window?!?!?!?!?        
        pool_2 = tf.nn.max_pool( tf.nn.tanh(tf.add( tf.nn.conv2d(tf.nn.max_pool(tf.nn.tanh(tf.add( tf.nn.conv2d(reshaped, conv_1_kernel, strides=[1, 1, 1, 1], padding='SAME'), conv_1_bias) ), ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='VALID'), conv_2_kernel, strides=[1, 1, 1, 1], padding='SAME'), conv_2_bias) ), ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='VALID')
        
        
        #time_max = tf.reduce_max(pool_2, axis=1, keepdims=False)
        time_max = pool_2

        #time_max = tf.maximum(pool_2, previous_max_tensor)
        global_pool = tf.reduce_mean(time_max, axis=[1, 2])
        #global_pool = tf.reduce_max(time_max, axis=[1, 2])
        dense_1 = tf.nn.tanh(tf.add(tf.matmul(global_pool, dense_1_w), dense_1_b))
        dense_2 = tf.nn.softmax(tf.add(tf.matmul(dense_1, dense_2_w), dense_2_b))
        
        
	#dense_2 = tf.cast(dense_2[0][0] + add_val_tensor, tf.int32)
        
	dense_2 = tf.cast(dense_2[0][0], tf.int32)
        
    y_out = session.run(dense_2,{
        in_tensor: mal_in,
        #previous_max_tensor: max_in
    })

    # print(y_out[0][0][0])
    print(y_out)
    
    #param10 = max_in
    #param9 = mal_in

    param8 = dense_2_b.eval()
    param7 = dense_2_w.eval()
    param6 = dense_1_b.eval()
    param5 = dense_1_w.eval()
    param4 = conv_2_bias.eval()
    param3 = conv_2_kernel.eval()
    param2 = conv_1_bias.eval()
    param1 = conv_1_kernel.eval()

    # param0 = embed_weights.eval()

    # ORDER MATTERS
    memList = [
    #param0,
    param1,
    mal_in,
    param2,
    param3,
    param4,
    #max_in,
    param5,
    param6,
    param7,
    param8,
    #out_add_vals,
    #out_mult_vals
    ]

    # about 37k floats after memories
    #mif.createMem(memList)

    
'''
# compare output above with real output - should match!!!

from keras.models import Model
layer_name = "time_distributed_1"
intermediate_layer_model = Model(inputs=model.input,
                                 outputs=model.get_layer(layer_name).output)
pred = intermediate_layer_model.predict(mal_in)
# print(pred[0][0][0])

pred = model.predict(mal_in)
print(pred)

# '''
