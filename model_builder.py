import pickle, gzip, glob, sys, keras, os
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'  # gets rid of AVX message
import random as rn
import numpy as np
import tensorflow as tf
os.environ['PYTHONHASHSEED'] = '0'
np.random.seed(37)
rn.seed(1254)
tf.set_random_seed(89)
from keras import optimizers
from keras import backend as K
from keras.models import load_model
from keras.layers import *
from keras.models import Sequential
from keras.losses import weighted_categorical_crossentropy
from keras.callbacks import CSVLogger, ModelCheckpoint
from keras.regularizers import *
from keras.utils.generic_utils import get_custom_objects
from keras.layers.advanced_activations import LeakyReLU, ELU
sys.path.insert(0, r'.\libraries')
from kerasLayers import *
from kerasExtras import *
elu = ELU(1)
elu.__name__ = "ELU"


def build_model(input_length, line_length, architecture, output_mode, extras=[]):
    if architecture not in ["cnn", "convlstm", "minconvrnn", "distcnn"]:
        raise ValueError("architecture must be one of cnn, convlstm, minconvrnn, distcnn")
    
    if architecture == "cnn":
        raise ValueError("cnn not yet implemented.")
        
    if output_mode not in ["binary", "malware_only", "full"]:
        raise ValueError("output_mode must be one of binary, malware_only, full")
    
    # handle extras
    
    vocab_size = 256
    
    model = Sequential()
    
    if "noembed" in extras:
        model.add(Lambda( reshape_operator_noembed, output_shape = reshape_shape_noembed, input_shape=(input_length,line_length) ))
    else:
        # ORIG SIZE
        # model.add(TimeDistributed(Embedding(vocab_size, 100), input_shape=(input_length,line_length)))
        
        
        model.add(TimeDistributed(Embedding(vocab_size, 100), input_shape=(input_length,line_length)))
        model.add(Lambda( reshape_operator, output_shape = reshape_shape ))
    
    if False:
        pass
        # implement regular CNN here? Not sure.
    elif architecture == "convlstm":
        model.add(ConvLSTM2D(50, 4, padding="same", return_sequences=True))
        model.add(ConvLSTM2D(25, 3, padding="same"))
        
    elif architecture == "minconvrnn":
        model.add(MinConvRNN(50, 5,  padding="same", activation="sigmoid", dropout=.5, return_sequences=True))
        model.add(MinConvRNN(25, 4,  padding="same", activation="sigmoid", dropout=.5))
        
    elif architecture == "distcnn":
        model.add(TimeDistributed(Conv2D(10, 5, padding="same",activation="tanh")))
        # model.add(TimeDistributed(Conv2D(50, 5, padding="same",activation="tanh", kernel_regularizer=regularizers.l1(0.005))))
        # model.add(TimeDistributed(Conv2D(30, 5, padding="same",activation="relu")))
        model.add(TimeDistributed(MaxPooling2D(pool_size=(2, 2))))
        
        # model.add(TimeDistributed(Conv2D(25, 5, padding="same",activation="tanh")))
        # model.add(TimeDistributed(Conv2D(20, 4, padding="same",activation="tanh")))
        # model.add(TimeDistributed(MaxPooling2D(pool_size=(2, 2))))
        
        model.add(TimeDistributed(Conv2D(25, 5, padding="same",activation="tanh")))
        # model.add(TimeDistributed(Conv2D(20, 4, padding="same",activation="relu")))
        model.add(TimeDistributed(MaxPooling2D(pool_size=(2, 2))))
        # model.add(TimeDistributed(Dropout(.1)))
        
        
        model.add(Lambda( max_operator, output_shape = max_shape ))
    
    
    model.add(GlobalMaxPooling2D())
    
    # other options maybe
    # model.add(GlobalAveragePooling2D())
    # model.add(Flatten())
    model.add(Dense(50, activation='tanh'))
    
    
    if output_mode == "binary":
        model.add(Dense(1, activation='sigmoid'))
        
    elif output_mode == "malware_only":
        model.add(Dense(9, activation='softmax'))
    
    elif output_mode == "full":
        model.add(Dense(11, activation='softmax'))
    
    
    
    
    
    
    return model