import gzip, numpy, pickle
# import keras
# from keras import backend as K
import numpy as np




def poolData(data):
    
    delItems = []
    cnt = 0
    for x in range(0, data.shape[1]):
        if cnt != 5:
            delItems.append(x)
        
        if cnt == 9:
            cnt = 0
        else:
            cnt += 1
    
    return np.delete(data, delItems, 1)

batch_size = 1

def loadDataGeneratorBatchesAndPool(assemblyVectorizedFile, maxNumSamples, writeToFile):
    readMe = gzip.open(assemblyVectorizedFile, "rb")
    writeMe = gzip.open(writeToFile, "w+b")
    numSamples = 0
    
    while True:
        try:
            assert numSamples < maxNumSamples
            
            xArr = []
            answers = []
            # for x in range(0,batch_size):
            fileArr = pickle.load(readMe)
            xArr.append(fileArr[0])
            answers.append(fileArr[1])
            
            train_x = numpy.asarray(xArr, dtype="float32") 
            # print(train_x[0][0:10])
            # disarrange(train_x, axis=1)
            # print(train_x[0][0:10])
            # print(0/0)
            # print(train_x[0][0:10])
            # print()
            # print(train_x[0][10:20])
            train_x = poolData(train_x)
            
            pickle.dump([train_x.tolist()[0], fileArr[1]], writeMe)
            # print()
            # print()
            # print(train_x[0][0:10])
            # print(0/0)
            
            ans = []
            for x in range(0,batch_size):
                num = answers.pop(0)[0]
                answer = [0]*9
                answer[num-1] = 1
                ans.append(answer)
                # print("ANSWER IS", num)
            train_y = numpy.asarray(ans, dtype="float32")
            
            numSamples += 1
            yield (train_x, train_y)
            
        except (EOFError, AssertionError) as e :
            del readMe
            readMe = gzip.open(assemblyVectorizedFile, "rb")
            numSamples = 0
            
            
def loadDataGeneratorBatchesAndPoolBinary(assemblyVectorizedFile, maxNumSamples, writeToFile):
    readMe = gzip.open(assemblyVectorizedFile, "rb")
    writeMe = gzip.open(writeToFile, "w+b")
    numSamples = 0
    
    while True:
        try:
            assert numSamples < maxNumSamples
            
            xArr = []
            answers = []
            # for x in range(0,batch_size):
            fileArr = pickle.load(readMe)
            xArr.append(fileArr[0])
            answers.append(fileArr[1])
            
            train_x = numpy.asarray(xArr, dtype="float32") 
            # print(train_x[0][0:10])
            # disarrange(train_x, axis=1)
            # print(train_x[0][0:10])
            # print(0/0)
            # print(train_x[0][0:10])
            # print()
            # print(train_x[0][10:20])
            train_x = poolData(train_x)
            
            pickle.dump([train_x.tolist()[0], fileArr[1]], writeMe)
            
            
            train_y = numpy.asarray(fileArr[1], dtype="float32")
            
            numSamples += 1
            yield (train_x, train_y)
            
        except (EOFError, AssertionError) as e :
            del readMe
            readMe = gzip.open(assemblyVectorizedFile, "rb")
            numSamples = 0
            
            
def window_stack(a, overlapSize=20, windowSize=25):
    n = a.shape[0] + 1
    # x[0:25], x[15:40], x[30:55].......
    # return np.stack( [a[i:i+width] for i in range(0,n-width, windowSize)], axis=0)
    return np.concatenate( [a[i:i+windowSize] for i in range(0,n-windowSize, overlapSize)], axis=0)
            
def loadDataGeneratorBatchesAndSlideWindow(assemblyVectorizedFile, maxNumSamples, writeToFile, overlapSize):
    readMe = gzip.open(assemblyVectorizedFile, "rb")
    writeMe = gzip.open(writeToFile, "w+b")
    numSamples = 0
    
    while True:
        try:
            assert numSamples < maxNumSamples
            
            xArr = []
            answers = []
            # for x in range(0,batch_size):
            fileArr = pickle.load(readMe)
            xArr.append(fileArr[0])
            answers.append(fileArr[1])
            
            train_x = numpy.asarray(xArr, dtype="float32") 
            # print(train_x[0][0:10])
            # disarrange(train_x, axis=1)
            # print(train_x[0][0:10])
            # print(0/0)
            # print(train_x[0][0:10])
            # print()
            # print(train_x[0][10:20])
            train_x = train_x[0]
            
            # print(train_x.shape)
            # print(train_x[0:25])
            train_x = window_stack(train_x, overlapSize=overlapSize)
            # print(train_x.shape)
            # print(train_x[25:50])
            # print(0/0)
            
            
            #make windows and stack on 0th axis
            
            
            pickle.dump([train_x.tolist(), fileArr[1]], writeMe)
            # print()
            # print()
            # print(train_x[0][0:10])
            # print(0/0)
            
            ans = []
            for x in range(0,batch_size):
                num = answers.pop(0)[0]
                answer = [0]*9
                answer[num-1] = 1
                ans.append(answer)
                # print("ANSWER IS", num)
            train_y = numpy.asarray(ans, dtype="float32")
            
            numSamples += 1
            yield (train_x, train_y)
            
        except (EOFError, AssertionError) as e :
            del readMe
            readMe = gzip.open(assemblyVectorizedFile, "rb")
            numSamples = 0
            
    
    
# proof of window stack
if __name__ == "__main__":
    test = np.arange(0,1000)
    test = test.reshape((100,10))
    # test = window_stack(test, overlapSize=1, windowSize=5)
    # print(test[:50])
    # print(test.shape)
    # test = test.reshape((int(480/5), 5, 10))
    # print(test[-1])
    print(window_stack(test, overlapSize=1, windowSize=5).shape)
    print(window_stack(test, overlapSize=4, windowSize=5).shape)
    
    
    
    
    
    
    
    